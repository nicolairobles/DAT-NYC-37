{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batte...</td>\n",
       "      <td>A sign stands outside the International Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.popsci.com/technology/article/2012-...</td>\n",
       "      <td>8471</td>\n",
       "      <td>{\"title\":\"The Fully Electronic Futuristic Star...</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "      <td>The Fully Electronic Futuristic Starting Gun T...</td>\n",
       "      <td>And that can be carried on a plane without the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.menshealth.com/health/flu-fighting-...</td>\n",
       "      <td>1164</td>\n",
       "      <td>{\"title\":\"Fruits that Fight the Flu fruits tha...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2240</td>\n",
       "      <td>258</td>\n",
       "      <td>11</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruits that Fight the Flu fruits that fight th...</td>\n",
       "      <td>Apples The most popular source of antioxidants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.dumblittleman.com/2007/12/10-foolpr...</td>\n",
       "      <td>6684</td>\n",
       "      <td>{\"title\":\"10 Foolproof Tips for Better Sleep \"...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2737</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>1</td>\n",
       "      <td>10 Foolproof Tips for Better Sleep</td>\n",
       "      <td>There was a period in my life when I had a lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bleacherreport.com/articles/1205138-the...</td>\n",
       "      <td>9006</td>\n",
       "      <td>{\"title\":\"The 50 Coolest Jerseys You Didn t Kn...</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12032</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0</td>\n",
       "      <td>The 50 Coolest Jerseys You Didn t Know Existed...</td>\n",
       "      <td>Jersey sales is a curious business Whether you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "1  http://www.popsci.com/technology/article/2012-...   8471   \n",
       "2  http://www.menshealth.com/health/flu-fighting-...   1164   \n",
       "3  http://www.dumblittleman.com/2007/12/10-foolpr...   6684   \n",
       "4  http://bleacherreport.com/articles/1205138-the...   9006   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "1  {\"title\":\"The Fully Electronic Futuristic Star...       recreation   \n",
       "2  {\"title\":\"Fruits that Fight the Flu fruits tha...           health   \n",
       "3  {\"title\":\"10 Foolproof Tips for Better Sleep \"...           health   \n",
       "4  {\"title\":\"The 50 Coolest Jerseys You Didn t Kn...           sports   \n",
       "\n",
       "  alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0               0.789131     2.055556           0.676471           0.205882   \n",
       "1               0.574147     3.677966           0.508021           0.288770   \n",
       "2               0.996526     2.382883           0.562016           0.321705   \n",
       "3               0.801248     1.543103           0.400000           0.100000   \n",
       "4               0.719157     2.676471           0.500000           0.222222   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  \\\n",
       "0           0.047059           0.023529   \n",
       "1           0.213904           0.144385   \n",
       "2           0.120155           0.042636   \n",
       "3           0.016667           0.000000   \n",
       "4           0.123457           0.043210   \n",
       "\n",
       "                         ...                          linkwordscore  \\\n",
       "0                        ...                                     24   \n",
       "1                        ...                                     40   \n",
       "2                        ...                                     55   \n",
       "3                        ...                                     24   \n",
       "4                        ...                                     14   \n",
       "\n",
       "   news_front_page  non_markup_alphanum_characters  numberOfLinks  \\\n",
       "0                0                            5424            170   \n",
       "1                0                            4973            187   \n",
       "2                0                            2240            258   \n",
       "3                0                            2737            120   \n",
       "4                0                           12032            162   \n",
       "\n",
       "   numwords_in_url  parametrizedLinkRatio  spelling_errors_ratio label  \\\n",
       "0                8               0.152941               0.079130     0   \n",
       "1                9               0.181818               0.125448     1   \n",
       "2               11               0.166667               0.057613     1   \n",
       "3                5               0.041667               0.100858     1   \n",
       "4               10               0.098765               0.082569     0   \n",
       "\n",
       "                                               title  \\\n",
       "0  IBM Sees Holographic Calls Air Breathing Batte...   \n",
       "1  The Fully Electronic Futuristic Starting Gun T...   \n",
       "2  Fruits that Fight the Flu fruits that fight th...   \n",
       "3                10 Foolproof Tips for Better Sleep    \n",
       "4  The 50 Coolest Jerseys You Didn t Know Existed...   \n",
       "\n",
       "                                                body  \n",
       "0  A sign stands outside the International Busine...  \n",
       "1  And that can be carried on a plane without the...  \n",
       "2  Apples The most popular source of antioxidants...  \n",
       "3  There was a period in my life when I had a lot...  \n",
       "4  Jersey sales is a curious business Whether you...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = pd.read_csv(\"https://github.com/ga-students/DAT-NYC-37/blob/master/lessons/lesson-13/assets/dataset/stumbleupon.tsv?raw=true\", sep='\\t')\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting \"Greenness\" Of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from [stumbleupon](https://www.stumbleupon.com/), a web page recommender.  \n",
    "\n",
    "A description of the columns is below\n",
    "\n",
    "#### What are 'evergreen' sites?\n",
    "\n",
    "Evergreen sites are those that are always relevant.  As opposed to breaking news or current events, evergreen websites are relevant no matter the time or season. \n",
    "\n",
    "*A sample of URLs is below, where `label = 1` are 'evergreen' websites*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "title|string|Title of the article\n",
    "body|string|Body text of article\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonlinkratio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonlinkratio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonlinkratio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonlinkratio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Objective: Predict if a given site will be evergreen based on the above features\n",
    "\n",
    "**Problem:** Some of the above features are text-only (`title`, `url`, `body`). How can I leverage the modeling techniques we've covered so far to utilize text based features?\n",
    "\n",
    "**Solution:** Transform text features into many numerical features.\n",
    "  - Count Vectorization\n",
    "  - Term frequency/inverse document frequency (TF-IDF) Vectorization.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Understanding Count Vectorization\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Count vectorization can be thought of as a simple word count across all documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: \n",
      "[u'advantages', u'advantages racesthe', u'air', u'air breathing', u'batteries', u'breathing', u'breathing batteries', u'bulls', u'bulls won', u'calls', u'calls air', u'chicago', u'chicago bulls', u'electronic', u'electronic calls', u'electronic futuristic', u'eliminates', u'eliminates advantages', u'fully', u'fully electronic', u'futuristic', u'futuristic starting', u'gun', u'gun eliminates', u'ibm', u'ibm sees', u'racesthe', u'racesthe chicago', u'sees', u'sees electronic', u'starting', u'starting gun', u'won']\n",
      "Feature counts: \n",
      "[[0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0]\n",
      " [1 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advantages</th>\n",
       "      <th>advantages racesthe</th>\n",
       "      <th>air</th>\n",
       "      <th>air breathing</th>\n",
       "      <th>batteries</th>\n",
       "      <th>breathing</th>\n",
       "      <th>breathing batteries</th>\n",
       "      <th>bulls</th>\n",
       "      <th>bulls won</th>\n",
       "      <th>calls</th>\n",
       "      <th>...</th>\n",
       "      <th>gun eliminates</th>\n",
       "      <th>ibm</th>\n",
       "      <th>ibm sees</th>\n",
       "      <th>racesthe</th>\n",
       "      <th>racesthe chicago</th>\n",
       "      <th>sees</th>\n",
       "      <th>sees electronic</th>\n",
       "      <th>starting</th>\n",
       "      <th>starting gun</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Article1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          advantages  advantages racesthe  air  air breathing  batteries  \\\n",
       "Article1           0                    0    1              1          1   \n",
       "Article2           1                    1    0              0          0   \n",
       "\n",
       "          breathing  breathing batteries  bulls  bulls won  calls ...   \\\n",
       "Article1          1                    1      0          0      1 ...    \n",
       "Article2          0                    0      1          1      0 ...    \n",
       "\n",
       "          gun eliminates  ibm  ibm sees  racesthe  racesthe chicago  sees  \\\n",
       "Article1               0    1         1         0                 0     1   \n",
       "Article2               1    0         0         1                 1     0   \n",
       "\n",
       "          sees electronic  starting  starting gun  won  \n",
       "Article1                1         0             0    0  \n",
       "Article2                0         1             1    1  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "titles = [\n",
    "    \"IBM Sees Electronic Calls Air Breathing Batteries\",\n",
    "    \"The Fully Electronic Futuristic Starting Gun That Eliminates Advantages in Races\"\n",
    "    \"The Chicago Bulls won\"\n",
    "]\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "count_vectorized_titles = count_vectorizer.fit_transform(titles)\n",
    "\n",
    "print \"Feature names: \\n\", count_vectorizer.get_feature_names()\n",
    "print \"Feature counts: \\n\", count_vectorized_titles.todense()\n",
    "print\n",
    "\n",
    "# Represent Count Vectorized results as a dataframe so we can preview it more easily.\n",
    "pd.DataFrame(\n",
    "    columns=count_vectorizer.get_feature_names(),\n",
    "    index=['Article1', 'Article2'],\n",
    "    data=count_vectorized_titles.todense()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Apply count vectorization to all titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Term-frequency, Inverse document frequency (Tf-Idf)\n",
    "\n",
    "An alternative bag-of-words approach to CountVectorizer is a Term Frequency - Inverse Document Frequency (TF-IDF) representation.\n",
    "\n",
    "TF-IDF uses the product of two intermediate values, the **Term Frequency** and **Inverse Document Frequency**.\n",
    "\n",
    "- **Term Frequency** is equivalent to CountVectorizer features, just the number of times a word appears in the document (i.e. count).\n",
    "\n",
    "- **Document Frequency** is the percentage of documents that a particular word appears in. \n",
    "\n",
    "For example, “the” would be 100% while “Syria” is much lower.  \n",
    "\n",
    "Inverse Document Frequency is just 1/Document Frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: \n",
      "[u'advantages', u'air', u'batteries', u'breathing', u'calls', u'electronic', u'eliminates', u'fully', u'futuristic', u'gun', u'ibm', u'races', u'sees', u'starting']\n",
      "Feature counts: \n",
      "[[ 0.          0.39204401  0.39204401  0.39204401  0.39204401  0.27894255\n",
      "   0.          0.          0.          0.          0.39204401  0.\n",
      "   0.39204401  0.        ]\n",
      " [ 0.36499647  0.          0.          0.          0.          0.25969799\n",
      "   0.36499647  0.36499647  0.36499647  0.36499647  0.          0.36499647\n",
      "   0.          0.36499647]]\n",
      "IDF weights [ 1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.\n",
      "  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511  1.40546511\n",
      "  1.40546511  1.40546511]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advantages</th>\n",
       "      <th>air</th>\n",
       "      <th>batteries</th>\n",
       "      <th>breathing</th>\n",
       "      <th>calls</th>\n",
       "      <th>electronic</th>\n",
       "      <th>eliminates</th>\n",
       "      <th>fully</th>\n",
       "      <th>futuristic</th>\n",
       "      <th>gun</th>\n",
       "      <th>ibm</th>\n",
       "      <th>races</th>\n",
       "      <th>sees</th>\n",
       "      <th>starting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Article1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392044</td>\n",
       "      <td>0.392044</td>\n",
       "      <td>0.392044</td>\n",
       "      <td>0.392044</td>\n",
       "      <td>0.278943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article2</th>\n",
       "      <td>0.364996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259698</td>\n",
       "      <td>0.364996</td>\n",
       "      <td>0.364996</td>\n",
       "      <td>0.364996</td>\n",
       "      <td>0.364996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          advantages       air  batteries  breathing     calls  electronic  \\\n",
       "Article1    0.000000  0.392044   0.392044   0.392044  0.392044    0.278943   \n",
       "Article2    0.364996  0.000000   0.000000   0.000000  0.000000    0.259698   \n",
       "\n",
       "          eliminates     fully  futuristic       gun       ibm     races  \\\n",
       "Article1    0.000000  0.000000    0.000000  0.000000  0.392044  0.000000   \n",
       "Article2    0.364996  0.364996    0.364996  0.364996  0.000000  0.364996   \n",
       "\n",
       "              sees  starting  \n",
       "Article1  0.392044  0.000000  \n",
       "Article2  0.000000  0.364996  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "titles = [\n",
    "    \"IBM Sees Electronic Calls Air Breathing Batteries\",\n",
    "    \"The Fully Electronic Futuristic Starting Gun That Eliminates Advantages in Races\"\n",
    "]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', sublinear_tf = False)\n",
    "tfidf_vectorized_titles = tfidf_vectorizer.fit_transform(titles)\n",
    "\n",
    "print \"Feature names: \\n\", tfidf_vectorizer.get_feature_names()\n",
    "print \"Feature counts: \\n\", tfidf_vectorized_titles.todense()\n",
    "print \"IDF weights\", tfidf_vectorizer.idf_\n",
    "\n",
    "\n",
    "# Represent Count Vectorized results as a dataframe so we can preview it more easily.\n",
    "pd.DataFrame(\n",
    "    columns=tfidf_vectorizer.get_feature_names(),\n",
    "    index=['Article1', 'Article2'],\n",
    "    data=tfidf_vectorized_titles.todense()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Determine Tf-Idf of title \n",
    "# Find the words with 100 highest and lowest inverse document frequency\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', sublinear_tf = False)\n",
    "\n",
    "tfidf_vectorizer.fit(data['title'].dropna())\n",
    "tfidf_vectorized_titles = vectorizer.transform(titles)\n",
    "\n",
    "feature_names         = tfidf_vectorizer.get_feature_names()  # Returns all feature names\n",
    "inverse_document_freq = tfidf_vectorizer.idf_  # Returns document frequencies\n",
    "\n",
    "tfidf = pd.DataFrame(\n",
    "    {\n",
    "        \"feature_names\": feature_names,\n",
    "        \"inverse_document_freq\": inverse_document_freq\n",
    "    }\n",
    ")\n",
    "\n",
    "sorted_tfidf = tfidf.sort_values(by='inverse_document_freq')\n",
    "\n",
    "sorted_tfidf.tail(100)\n",
    "sorted_tfidf.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Demo: Use of the Count Vectorizer with ngrams\n",
    " \n",
    " We can use the `ngram_range` parameter to find ngrams -- groups of n words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: \n",
      "[u'advantages', u'advantages races', u'air', u'air breathing', u'batteries', u'breathing', u'breathing batteries', u'calls', u'calls air', u'electronic', u'electronic calls', u'electronic futuristic', u'eliminates', u'eliminates advantages', u'fully', u'fully electronic', u'futuristic', u'futuristic starting', u'gun', u'gun eliminates', u'ibm', u'ibm sees', u'races', u'sees', u'sees electronic', u'starting', u'starting gun']\n",
      "Feature counts: \n",
      "[[0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advantages</th>\n",
       "      <th>advantages races</th>\n",
       "      <th>air</th>\n",
       "      <th>air breathing</th>\n",
       "      <th>batteries</th>\n",
       "      <th>breathing</th>\n",
       "      <th>breathing batteries</th>\n",
       "      <th>calls</th>\n",
       "      <th>calls air</th>\n",
       "      <th>electronic</th>\n",
       "      <th>...</th>\n",
       "      <th>futuristic starting</th>\n",
       "      <th>gun</th>\n",
       "      <th>gun eliminates</th>\n",
       "      <th>ibm</th>\n",
       "      <th>ibm sees</th>\n",
       "      <th>races</th>\n",
       "      <th>sees</th>\n",
       "      <th>sees electronic</th>\n",
       "      <th>starting</th>\n",
       "      <th>starting gun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Article1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Article2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          advantages  advantages races  air  air breathing  batteries  \\\n",
       "Article1           0                 0    1              1          1   \n",
       "Article2           1                 1    0              0          0   \n",
       "\n",
       "          breathing  breathing batteries  calls  calls air  electronic  \\\n",
       "Article1          1                    1      1          1           1   \n",
       "Article2          0                    0      0          0           1   \n",
       "\n",
       "              ...       futuristic starting  gun  gun eliminates  ibm  \\\n",
       "Article1      ...                         0    0               0    1   \n",
       "Article2      ...                         1    1               1    0   \n",
       "\n",
       "          ibm sees  races  sees  sees electronic  starting  starting gun  \n",
       "Article1         1      0     1                1         0             0  \n",
       "Article2         0      1     0                0         1             1  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the inclusion of ngram_range\n",
    "count_vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "count_vectorized_titles = count_vectorizer.fit_transform(titles)\n",
    "\n",
    "print \"Feature names: \\n\", count_vectorizer.get_feature_names()\n",
    "print \"Feature counts: \\n\", count_vectorized_titles.todense()\n",
    "print\n",
    "\n",
    "# Represent Count Vectorized results as a dataframe so we can preview it more easily.\n",
    "pd.DataFrame(\n",
    "    columns=count_vectorizer.get_feature_names(),\n",
    "    index=['Article1', 'Article2'],\n",
    "    data=count_vectorized_titles.todense()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Review Exercise\n",
    "\n",
    "## Exercise Demo: Build a random forest model to predict evergreeness of a website using the title features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC [ 0.81448427  0.82517325  0.81615213], Average AUC 0.818603217242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# 1. We need to fill NaN's with an empty string, otherwise the count vectorizer will fail.\n",
    "titles = data['title'].fillna('')\n",
    "\n",
    "# 2. Use `fit` to learn the vocabulary of the titles\n",
    "count_vectorizer.fit(titles)\n",
    "\n",
    "# 3. Use `tranform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "# Hint: Steps 2 & 3 can be combined by using `count_vectorizer.fit_transform(titles)`\n",
    "X = count_vectorizer.transform(titles).toarray()\n",
    "y = data['label']\n",
    "\n",
    "# 4. Define our RandomForestClassifier model. It will fit 20 decision trees, each on a random subsample of the dataset.\n",
    "rf_model = RandomForestClassifier(n_estimators = 20)\n",
    "    \n",
    "scores = cross_val_score(rf_model, X, y, scoring='roc_auc')\n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Build a random forest model to predict evergreeness of a website using the title features and quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of documents to be vectorized (input): \n",
      "0    IBM Sees Holographic Calls Air Breathing Batte...\n",
      "1    The Fully Electronic Futuristic Starting Gun T...\n",
      "2    Fruits that Fight the Flu fruits that fight th...\n",
      "3                  10 Foolproof Tips for Better Sleep \n",
      "4    The 50 Coolest Jerseys You Didn t Know Existed...\n",
      "Name: title, dtype: object\n",
      "\n",
      "Vectorized Output sample: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 000</th>\n",
       "      <th>000</th>\n",
       "      <th>000 deaths</th>\n",
       "      <th>000 eye</th>\n",
       "      <th>000 feet</th>\n",
       "      <th>000 fine</th>\n",
       "      <th>000 lbs</th>\n",
       "      <th>000 legos</th>\n",
       "      <th>000 macs</th>\n",
       "      <th>...</th>\n",
       "      <th>アンブロワジー evan</th>\n",
       "      <th>スタイルアリーナ</th>\n",
       "      <th>スタイルアリーナ style</th>\n",
       "      <th>南方周末</th>\n",
       "      <th>南方周末 首页</th>\n",
       "      <th>可乐鸡翅</th>\n",
       "      <th>可乐鸡翅 cooking</th>\n",
       "      <th>東京のストリートファッション最新情報</th>\n",
       "      <th>東京のストリートファッション最新情報 スタイルアリーナ</th>\n",
       "      <th>首页</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  00 000  000  000 deaths  000 eye  000 feet  000 fine  000 lbs  \\\n",
       "0   0       0    0           0        0         0         0        0   \n",
       "1   0       0    0           0        0         0         0        0   \n",
       "2   0       0    0           0        0         0         0        0   \n",
       "3   0       0    0           0        0         0         0        0   \n",
       "4   0       0    0           0        0         0         0        0   \n",
       "\n",
       "   000 legos  000 macs ...  アンブロワジー evan  スタイルアリーナ  スタイルアリーナ style  南方周末  \\\n",
       "0          0         0 ...             0         0               0     0   \n",
       "1          0         0 ...             0         0               0     0   \n",
       "2          0         0 ...             0         0               0     0   \n",
       "3          0         0 ...             0         0               0     0   \n",
       "4          0         0 ...             0         0               0     0   \n",
       "\n",
       "   南方周末 首页  可乐鸡翅  可乐鸡翅 cooking  東京のストリートファッション最新情報  \\\n",
       "0        0     0             0                   0   \n",
       "1        0     0             0                   0   \n",
       "2        0     0             0                   0   \n",
       "3        0     0             0                   0   \n",
       "4        0     0             0                   0   \n",
       "\n",
       "   東京のストリートファッション最新情報 スタイルアリーナ  首页  \n",
       "0                            0   0  \n",
       "1                            0   0  \n",
       "2                            0   0  \n",
       "3                            0   0  \n",
       "4                            0   0  \n",
       "\n",
       "[5 rows x 40322 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make our lives easier, let's define a simple utility function to convert an array or series text of\n",
    "# text documents into  a count vectorized dataframe:\n",
    "def count_vectorized_dataframe(documents, ngram_range=(1, 2)):\n",
    "    count_vectorizer = CountVectorizer(stop_words='english', ngram_range=ngram_range)\n",
    "    count_vectorized_results = count_vectorizer.fit_transform(documents)\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        columns=count_vectorizer.get_feature_names(),\n",
    "        data=count_vectorized_results.todense()\n",
    "    )\n",
    "\n",
    "# Example Usage\n",
    "title_text = data['title'].fillna('')\n",
    "\n",
    "print \"Preview of documents to be vectorized (input): \"\n",
    "print title_text.head()\n",
    "\n",
    "count_vectorized_titles = count_vectorized_dataframe(data['title'].fillna(''))\n",
    "\n",
    "print \"\\nVectorized Output sample: \"\n",
    "count_vectorized_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 000</th>\n",
       "      <th>000</th>\n",
       "      <th>000 deaths</th>\n",
       "      <th>000 eye</th>\n",
       "      <th>000 feet</th>\n",
       "      <th>000 fine</th>\n",
       "      <th>000 lbs</th>\n",
       "      <th>000 legos</th>\n",
       "      <th>000 macs</th>\n",
       "      <th>...</th>\n",
       "      <th>南方周末</th>\n",
       "      <th>南方周末 首页</th>\n",
       "      <th>可乐鸡翅</th>\n",
       "      <th>可乐鸡翅 cooking</th>\n",
       "      <th>東京のストリートファッション最新情報</th>\n",
       "      <th>東京のストリートファッション最新情報 スタイルアリーナ</th>\n",
       "      <th>首页</th>\n",
       "      <th>embed_ratio</th>\n",
       "      <th>image_ratio</th>\n",
       "      <th>html_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.245831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088652</td>\n",
       "      <td>0.203490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120536</td>\n",
       "      <td>0.226402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035343</td>\n",
       "      <td>0.265656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050473</td>\n",
       "      <td>0.228887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  00 000  000  000 deaths  000 eye  000 feet  000 fine  000 lbs  \\\n",
       "0   0       0    0           0        0         0         0        0   \n",
       "1   0       0    0           0        0         0         0        0   \n",
       "2   0       0    0           0        0         0         0        0   \n",
       "3   0       0    0           0        0         0         0        0   \n",
       "4   0       0    0           0        0         0         0        0   \n",
       "\n",
       "   000 legos  000 macs     ...      南方周末  南方周末 首页  可乐鸡翅  可乐鸡翅 cooking  \\\n",
       "0          0         0     ...         0        0     0             0   \n",
       "1          0         0     ...         0        0     0             0   \n",
       "2          0         0     ...         0        0     0             0   \n",
       "3          0         0     ...         0        0     0             0   \n",
       "4          0         0     ...         0        0     0             0   \n",
       "\n",
       "   東京のストリートファッション最新情報  東京のストリートファッション最新情報 スタイルアリーナ  首页  embed_ratio  \\\n",
       "0                   0                            0   0          0.0   \n",
       "1                   0                            0   0          0.0   \n",
       "2                   0                            0   0          0.0   \n",
       "3                   0                            0   0          0.0   \n",
       "4                   0                            0   0          0.0   \n",
       "\n",
       "   image_ratio  html_ratio  \n",
       "0     0.003883    0.245831  \n",
       "1     0.088652    0.203490  \n",
       "2     0.120536    0.226402  \n",
       "3     0.035343    0.265656  \n",
       "4     0.050473    0.228887  \n",
       "\n",
       "[5 rows x 40325 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: We want to repeat the above, but with these features as well:\n",
    "\n",
    "# Step 1: Prepare the input data by selecting relevant columns and dummy-encoding categorical vars\n",
    "quantitative_features = [\n",
    "    'embed_ratio',\n",
    "    'image_ratio',\n",
    "    'html_ratio'\n",
    "]\n",
    "\n",
    "# Dummy encoding\n",
    "\n",
    "quantitative_features = data[quantitative_features]\n",
    "\n",
    "# Horizontally concantenate categorical features, quantitative features, and count_vectorized_title features into a single DF\n",
    "X = pd.concat([count_vectorized_titles, quantitative_features], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV AUC [ 0.78584518  0.80038702  0.79039878], Average AUC 0.792210329434\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Repeat the process in previous exercise, only with our new dataframe\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=15)\n",
    "scores = cross_val_score(rf_model, X.values, y, cv=2, scoring='roc_auc')\n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Exercise: Build a random forest model to predict evergreeness of a website using only the features extracted from the `body` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "body_documents = data['body'].fillna('')\n",
    "X = count_vectorized_dataframe(body_documents)\n",
    "\n",
    "# Same as before, but with a different input\n",
    "rf_model = RandomForestClassifier(n_estimators=20)\n",
    "scores = cross_val_score(rf_model, X.values, y, scoring='roc_auc')\n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Exercise Repeat above exercises using `TfIdfVectorizer` instead of `CountVectorizer` - is this an improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
