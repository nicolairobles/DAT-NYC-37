{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target classes ['setosa' 'versicolor' 'virginica']\n",
      "Features names ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot\n",
    "import sklearn.datasets \n",
    "\n",
    "iris_dataset = sklearn.datasets.load_iris()\n",
    "\n",
    "y = iris_dataset.target\n",
    "\n",
    "# labels\n",
    "print \"Target classes\", iris_dataset.target_names\n",
    "print \"Features names\", iris_dataset.feature_names\n",
    "\n",
    "# Actual data\n",
    "print iris_dataset.data \n",
    "print iris_dataset.target\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.977777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  # Our classifier\n",
    "from sklearn.cross_validation import train_test_split  # Train-test \n",
    "\n",
    "X_iris = iris_dataset.data\n",
    "y_iris = iris_dataset.target\n",
    "\n",
    "# 2. Split dataset into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.3, random_state=1)\n",
    "\n",
    "# 3. Define our model\n",
    "k = 5\n",
    "knn_classif = KNeighborsClassifier(k)\n",
    "\n",
    "# 4. Fit our model\n",
    "knn_classif.fit(X_train, y_train)\n",
    "\n",
    "# 5. Score\n",
    "print \"Train score: \", knn_classif.score(X_test, y_test)\n",
    "\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1 => 0.933333333333\n",
      "fold: 2 => 1.0\n",
      "fold: 3 => 1.0\n",
      "fold: 4 => 0.966666666667\n",
      "fold: 5 => 0.933333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "N_SAMPLES = 100\n",
    "scores = []\n",
    "\n",
    "kfolds = 5\n",
    "iris_folds = KFold(len(X_iris), kfolds, shuffle=True)\n",
    "\n",
    "# Subsetting:\n",
    "def knn_classif(X_train, y_train, X_test, y_test, k = 5):\n",
    "    # 3. Define our model\n",
    "    knn_classif = KNeighborsClassifier(k)\n",
    "\n",
    "    # 4. Fit our model\n",
    "    knn_classif.fit(X_train, y_train)\n",
    "\n",
    "    # 5. Score\n",
    "    return knn_classif.score(X_test, y_test)\n",
    "    \n",
    "i = 1\n",
    "for fold in iris_folds:\n",
    "    #     print \"TRAINING INDICES: \", fold[0]\n",
    "    #     print \"TEST INDICES: \", fold[1]\n",
    "    \n",
    "    X_train_fold = X_iris[fold[0], :]\n",
    "    X_test_fold  = X_iris[fold[1], :]\n",
    "        \n",
    "    y_train_fold = y_iris[fold[0]]\n",
    "    y_test_fold  = y_iris[fold[1]]\n",
    "\n",
    "    print \"fold: %s => %s\" % (i, knn_classif(X_train_fold, y_train_fold, X_test_fold, y_test_fold))\n",
    "    \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "knn_classif() takes at least 4 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-12dd0838a418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_SAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"k: %s => %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mknn_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_SAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: knn_classif() takes at least 4 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "for k in range(2, N_SAMPLES):\n",
    "    print \"k: %s => %0.3f\" % (k, knn_classif(k))\n",
    "    \n",
    "scores = [knn_classif(k) for k in range(2, N_SAMPLES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "98\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1110def90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(2, N_SAMPLES), scores)\n",
    "\n",
    "print len(scores)\n",
    "print len(range(2, N_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Best score 0.966666666667\n",
      "mean: 0.94000, std: 0.08270, params: {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.06291, params: {'n_neighbors': 2, 'weights': 'distance'}\n",
      "mean: 0.96000, std: 0.06291, params: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.06291, params: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "mean: 0.94667, std: 0.08162, params: {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.06291, params: {'n_neighbors': 4, 'weights': 'distance'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "mean: 0.94000, std: 0.09096, params: {'n_neighbors': 6, 'weights': 'uniform'}\n",
      "mean: 0.95333, std: 0.07582, params: {'n_neighbors': 6, 'weights': 'distance'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "mean: 0.96667, std: 0.06968, params: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "mean: 0.94667, std: 0.09069, params: {'n_neighbors': 8, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 8, 'weights': 'distance'}\n",
      "mean: 0.96000, std: 0.07430, params: {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 9, 'weights': 'distance'}\n",
      "mean: 0.94667, std: 0.10432, params: {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "mean: 0.95333, std: 0.07582, params: {'n_neighbors': 10, 'weights': 'distance'}\n",
      "mean: 0.94667, std: 0.08990, params: {'n_neighbors': 11, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 11, 'weights': 'distance'}\n",
      "mean: 0.94000, std: 0.09096, params: {'n_neighbors': 12, 'weights': 'uniform'}\n",
      "mean: 0.95333, std: 0.07582, params: {'n_neighbors': 12, 'weights': 'distance'}\n",
      "mean: 0.95333, std: 0.07582, params: {'n_neighbors': 13, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 13, 'weights': 'distance'}\n",
      "mean: 0.96000, std: 0.06291, params: {'n_neighbors': 14, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 14, 'weights': 'distance'}\n",
      "mean: 0.94667, std: 0.07681, params: {'n_neighbors': 15, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 15, 'weights': 'distance'}\n",
      "mean: 0.96000, std: 0.07430, params: {'n_neighbors': 16, 'weights': 'uniform'}\n",
      "mean: 0.96667, std: 0.06968, params: {'n_neighbors': 16, 'weights': 'distance'}\n",
      "mean: 0.94667, std: 0.07681, params: {'n_neighbors': 17, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 17, 'weights': 'distance'}\n",
      "mean: 0.95333, std: 0.08912, params: {'n_neighbors': 18, 'weights': 'uniform'}\n",
      "mean: 0.96667, std: 0.06968, params: {'n_neighbors': 18, 'weights': 'distance'}\n",
      "mean: 0.94667, std: 0.08911, params: {'n_neighbors': 19, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 19, 'weights': 'distance'}\n",
      "mean: 0.94667, std: 0.11093, params: {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 20, 'weights': 'distance'}\n",
      "mean: 0.94667, std: 0.08990, params: {'n_neighbors': 21, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 21, 'weights': 'distance'}\n",
      "mean: 0.93333, std: 0.11156, params: {'n_neighbors': 22, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 22, 'weights': 'distance'}\n",
      "mean: 0.93333, std: 0.11103, params: {'n_neighbors': 23, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 23, 'weights': 'distance'}\n",
      "mean: 0.93333, std: 0.11103, params: {'n_neighbors': 24, 'weights': 'uniform'}\n",
      "mean: 0.96000, std: 0.07317, params: {'n_neighbors': 24, 'weights': 'distance'}\n",
      "mean: 0.93333, std: 0.11103, params: {'n_neighbors': 25, 'weights': 'uniform'}\n",
      "mean: 0.95333, std: 0.07582, params: {'n_neighbors': 25, 'weights': 'distance'}\n",
      "mean: 0.92667, std: 0.12030, params: {'n_neighbors': 26, 'weights': 'uniform'}\n",
      "mean: 0.95333, std: 0.07582, params: {'n_neighbors': 26, 'weights': 'distance'}\n",
      "mean: 0.92000, std: 0.11944, params: {'n_neighbors': 27, 'weights': 'uniform'}\n",
      "mean: 0.94667, std: 0.08990, params: {'n_neighbors': 27, 'weights': 'distance'}\n",
      "mean: 0.92667, std: 0.12030, params: {'n_neighbors': 28, 'weights': 'uniform'}\n",
      "mean: 0.95333, std: 0.07582, params: {'n_neighbors': 28, 'weights': 'distance'}\n",
      "mean: 0.92667, std: 0.11581, params: {'n_neighbors': 29, 'weights': 'uniform'}\n",
      "mean: 0.94667, std: 0.07773, params: {'n_neighbors': 29, 'weights': 'distance'}\n",
      "mean: 0.92000, std: 0.11537, params: {'n_neighbors': 30, 'weights': 'uniform'}\n",
      "mean: 0.94667, std: 0.07773, params: {'n_neighbors': 30, 'weights': 'distance'}\n",
      "mean: 0.92667, std: 0.11326, params: {'n_neighbors': 31, 'weights': 'uniform'}\n",
      "mean: 0.94667, std: 0.07773, params: {'n_neighbors': 31, 'weights': 'distance'}\n",
      "mean: 0.91333, std: 0.13110, params: {'n_neighbors': 32, 'weights': 'uniform'}\n",
      "mean: 0.94667, std: 0.07773, params: {'n_neighbors': 32, 'weights': 'distance'}\n",
      "mean: 0.92000, std: 0.12390, params: {'n_neighbors': 33, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 33, 'weights': 'distance'}\n",
      "mean: 0.91333, std: 0.13110, params: {'n_neighbors': 34, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 34, 'weights': 'distance'}\n",
      "mean: 0.91333, std: 0.12274, params: {'n_neighbors': 35, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 35, 'weights': 'distance'}\n",
      "mean: 0.92000, std: 0.12390, params: {'n_neighbors': 36, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 36, 'weights': 'distance'}\n",
      "mean: 0.92000, std: 0.12390, params: {'n_neighbors': 37, 'weights': 'uniform'}\n",
      "mean: 0.93333, std: 0.09145, params: {'n_neighbors': 37, 'weights': 'distance'}\n",
      "mean: 0.92000, std: 0.12390, params: {'n_neighbors': 38, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 38, 'weights': 'distance'}\n",
      "mean: 0.92000, std: 0.12390, params: {'n_neighbors': 39, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 39, 'weights': 'distance'}\n",
      "mean: 0.92667, std: 0.11150, params: {'n_neighbors': 40, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 40, 'weights': 'distance'}\n",
      "mean: 0.92667, std: 0.11150, params: {'n_neighbors': 41, 'weights': 'uniform'}\n",
      "mean: 0.93333, std: 0.09145, params: {'n_neighbors': 41, 'weights': 'distance'}\n",
      "mean: 0.92000, std: 0.11983, params: {'n_neighbors': 42, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 42, 'weights': 'distance'}\n",
      "mean: 0.91333, std: 0.12500, params: {'n_neighbors': 43, 'weights': 'uniform'}\n",
      "mean: 0.93333, std: 0.09145, params: {'n_neighbors': 43, 'weights': 'distance'}\n",
      "mean: 0.90667, std: 0.12377, params: {'n_neighbors': 44, 'weights': 'uniform'}\n",
      "mean: 0.93333, std: 0.07877, params: {'n_neighbors': 44, 'weights': 'distance'}\n",
      "mean: 0.90667, std: 0.12377, params: {'n_neighbors': 45, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 45, 'weights': 'distance'}\n",
      "mean: 0.90667, std: 0.12377, params: {'n_neighbors': 46, 'weights': 'uniform'}\n",
      "mean: 0.93333, std: 0.07877, params: {'n_neighbors': 46, 'weights': 'distance'}\n",
      "mean: 0.90667, std: 0.12377, params: {'n_neighbors': 47, 'weights': 'uniform'}\n",
      "mean: 0.92667, std: 0.11150, params: {'n_neighbors': 47, 'weights': 'distance'}\n",
      "mean: 0.89333, std: 0.13595, params: {'n_neighbors': 48, 'weights': 'uniform'}\n",
      "mean: 0.94000, std: 0.07895, params: {'n_neighbors': 48, 'weights': 'distance'}\n",
      "mean: 0.90000, std: 0.12211, params: {'n_neighbors': 49, 'weights': 'uniform'}\n",
      "mean: 0.93333, std: 0.09145, params: {'n_neighbors': 49, 'weights': 'distance'}\n",
      "Best score was 0.967 at k={'n_neighbors': 7, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Minimum three input for cross validation\n",
    "\n",
    "# 1. Define the classifier\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "# 2. Define the parameter space\n",
    "parameter_space = {\n",
    "    'n_neighbors': range(2, 50),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "KNeighborsClassifier?\n",
    "\n",
    "# 3. Define how to validate the model\n",
    "cross_validator = KFold(len(X_iris), 20)\n",
    "\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator=classifier, \n",
    "    param_grid=parameter_space, \n",
    "    cv=cross_validator\n",
    ")\n",
    "\n",
    "# Fit is a common function  in SKLearn\n",
    "gridsearch.fit(X_iris, y_iris)\n",
    "\n",
    "print \"Best Params\", gridsearch.best_params_\n",
    "print \"Best score\", gridsearch.best_score_\n",
    "for grid_score in gridsearch.grid_scores_:\n",
    "    print grid_score\n",
    "\n",
    "print \"Best score was %0.3f at k=%s\" % (gridsearch.best_score_, gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    " - How to choose parameters of:\n",
    "   - Model?\n",
    "   - Train/Test split?\n",
    "   - Model evaluation\n",
    "\n",
    "### Train test split:\n",
    "   - Keep ~70% of data\n",
    "   - Test ~30% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arr = np.array(range(1, 100))\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "kfolds = KFold(20, 4)\n",
    "\n",
    "num = 1\n",
    "for fold in kfolds:\n",
    "    print \"Fold: %s\" % num\n",
    "    \n",
    "    print \"Training indices\", fold[0]\n",
    "    print \"Test indices\", fold[1]\n",
    "    print \"\\n\"\n",
    "    \n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
