{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT-NYC-37 | Lab 15 | Natural Language Processing and Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import feature_extraction, ensemble, cross_validation, metrics\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is about sentiments on Amazon reviews. The data is in a \"raw\" format where the review and it's score are separated by tabs (`\\t` character). We'll first need to parse it.\n",
    "\n",
    "Here's a sample:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>\n",
    "<pre>\n",
    "\\tIt clicks into place in a way that makes you wonder how long that mechanism would last.\\t0\n",
    "\\tI went on Motorola's website and followed all directions, but could not get it to pair again.\\t0\n",
    "</pre>\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print sklearn.__version__\n",
    "\n",
    "reviews = []\n",
    "sentiments = []\n",
    "\n",
    "with open(os.path.join('..', 'datasets', 'amazon-reviews.txt')) as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        review, sentiment = line.split('\\t')\n",
    "        sentiment = np.nan if sentiment == '' else int(sentiment)\n",
    "\n",
    "        reviews.append(review)\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "df = pd.DataFrame({'review': reviews, 'sentiment': sentiments})\n",
    "                                                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I try not to adjust the volume setting to avoi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I thought Motorola made reliable products!.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Battery for Motorola Razr.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I try not to adjust the volume setting to avoi...        NaN\n",
       "1  So there is no way for me to plug it in here i...        0.0\n",
       "2                        Good case, Excellent value.        1.0\n",
       "3        I thought Motorola made reliable products!.        NaN\n",
       "4                         Battery for Motorola Razr.        NaN"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace = True) # Let's drop NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  sentiment\n",
       "1   So there is no way for me to plug it in here i...        0.0\n",
       "2                         Good case, Excellent value.        1.0\n",
       "5                              Great for the jawbone.        1.0\n",
       "10  Tied to charger for conversations lasting more...        0.0\n",
       "11                                  The mic is great.        1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.review\n",
    "y = df.sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part I: Modeling text features using `CountVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CountVectorizer` converts a collection of text into a matrix of features.  Each row will be a sample (an article or piece of text) and each column will be a text feature (usually a count or binary feature per word).\n",
    "\n",
    "**`CountVectorizer` takes a column of text and creates a new dataset.**  It generates a feature for every word in all of the pieces of text.\n",
    "\n",
    "CAUTION: Using all of the words can be useful, but we may need to use regularization to avoid overfitting.  Otherwise, rare words may cause the model to overfit and not generalize.\n",
    "\n",
    "(And check http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html as needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Defining and transforming the input using `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Instantiate a new CountVectorizer Using english stop words\n",
    "\n",
    "# Reminder: \"Stop words\" are non-content words.  (e.g. 'to', 'the', and 'it')\n",
    "# They arenâ€™t helpful for prediction, so we remove them.\n",
    "# We'll almost always want to specify `stop_words = 'english'` to exclude stop words\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizers are like other models in `sklearn`:\n",
    "- We create a vectorizer object with the parameters of our feature space\n",
    "- We fit a vectorizer to learn the vocabulary\n",
    "- We transform a set of text into that feature space\n",
    "\n",
    "Note: there is a distinction between fit and transform:\n",
    "- We fit from our training set.  This is part of the model building process, so we don't look at our test set\n",
    "- We transform our test set using our model fit on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Call `fit` on your count vectorizer, passing in the appropriate input.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Transform the appropriate input into a count vectorized result.\n",
    "\n",
    "# To ensure you did this step correctly, preview first 10 feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "While dense matrices store every entry in the matrix, sparse matrices only store the nonzero entries.  Sparse matrices don't have a lot of extra features, and some algorithms may not work for them so you use them when you need to work with matrices that would be too big for the computer to handle them, but they are mostly zero, so they compress easily.  You can convert from sparse matrices to dense matrices with `.todense()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tip:\n",
    "# X_transformed.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q: What are the 10 most commonly used words in our training set?\n",
    "\n",
    "# TODO: YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split your data via train/test split using 30% of the dataset for training. Use `random_state=1` \n",
    "# so we can compare our results as a class\n",
    "\n",
    "# TODO: YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training a Classifier with Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build a random forest model to predict \"sentiment\".\n",
    "\n",
    "*Use the Sklearn documentation as necessary for these steps!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Review Q: Why might we use a Random Forest model here instead of a decision tree?\n",
    "\n",
    "# YOUR ANSWER HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Define a RandomForestClassifier that will train 20 decision trees.\n",
    "\n",
    "# YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Fit your RandomForestClassifier to your training data\n",
    "\n",
    "# YOUR CODE HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 4: Evaluating your model using AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: The following code generate an ROC curve and calculates the corresponding AUC score.\n",
    "# You'll need to replace the appropriate variables to get this to run\n",
    "\n",
    "test_y_hat = rf_model.predict_proba(test_X_transformed)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_y, test_y_hat[:, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label = 'ROC curve (area = %0.4f)' % metrics.auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([.0, 1.])\n",
    "plt.ylim([.0, 1.1])\n",
    "plt.xlabel('FPR/Fall-out')\n",
    "plt.ylabel('TPR/Sensitivity')\n",
    "plt.title('Training Sentiment ROC')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# plt.figure()\n",
    "# sns.distplot(fpr, color=\"red\", bins=10)\n",
    "# sns.distplot(tpr, color=\"green\", bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Now use the same process to generate an ROC score on the training dataset. Are you overfitting? \n",
    "# Why/why not? And if so, what can you do about it?\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Review Q: What is AUC score? Why are we using it?\n",
    "\n",
    "# YOUR ANSWER HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Directions: Redo the analysis above with `TfidfVectorizer` instead of `CountVectorizer`. Use 10 estimators for your Random Forest Classifier.  What results do you get?\n",
    "\n",
    "(Check http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: YOUR CODE AND RESULTS HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q: What words have the highest Tf-Idf? What does this indicate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Questions/Exercises:\n",
    "\n",
    "- Which features are most important? (hint: Read the docs: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- Use `cross_val_score` instead of a simple train/test split. How much does your model improve?\n",
    "- In your own words*, describe what `cross_val_score` is doing\n",
    "- Try including larger n_grams (e.g. 2 or 3) in your analysis. Does this improve your results?\n",
    "- What other strategies can you use to improve your results?\n",
    "- Why might using KNN be a bad idea on this dataset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
